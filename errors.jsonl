{"id": "batch_req_690e39f075a48190a35becd8968879eb", "custom_id": "request-0", "response": {"status_code": 400, "request_id": "0fa3ac00b04d6f9773406873ac43e0bc", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_690e39ef47bc8190bc6956ee83fd0c0c", "custom_id": "request-1", "response": {"status_code": 400, "request_id": "aba5db241ed8cc6f4925017e6d80590a", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_690e39ef3b908190b22b469028d00709", "custom_id": "request-2", "response": {"status_code": 0, "request_id": "", "body": {}}, "error": null}
{"id": "batch_req_690e39ef35d88190ab528420c5c48ea8", "custom_id": "request-3", "response": {"status_code": 400, "request_id": "5fa20eb0e75efa3b99c29e8ef1701c23", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_690e39ef33648190b7bd6c6e764b2209", "custom_id": "request-4", "response": {"status_code": 400, "request_id": "5f7d6a6d03538940d04b6a906ece140c", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_690e39ef35ec819080f9a94e46753581", "custom_id": "request-5", "response": {"status_code": 400, "request_id": "69305959fc58109e50d5f84cfbf4db37", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_690e39ef36b88190a221be7444e911bd", "custom_id": "request-6", "response": {"status_code": 400, "request_id": "ed8d53cf6b60d3643d3bd703946b36ea", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_690e39ef520c81909827cd889bdf5b7e", "custom_id": "request-7", "response": {"status_code": 400, "request_id": "b292da30b286027f2c6517949001355a", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_690e39ef43788190ae8cf1bc5db51f3c", "custom_id": "request-8", "response": {"status_code": 400, "request_id": "b32c49d107d4867e0fcd5e43c3676959", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_690e39ef35148190bc2e4bef7f3c0219", "custom_id": "request-9", "response": {"status_code": 400, "request_id": "d2768f096ea2fcda123fe25d3a96ba9c", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_690e39f02fa48190be3e5bdbbd2fbc59", "custom_id": "request-10", "response": {"status_code": 400, "request_id": "c84cb0b0d226a6a3a0edffb7024328ae", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_690e39f02a448190aa33a7bb908b70e4", "custom_id": "request-11", "response": {"status_code": 400, "request_id": "2f013927652db28c881e9c8fef65c63a", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_690e39f02f8c8190a97ac24148870872", "custom_id": "request-12", "response": {"status_code": 400, "request_id": "32dbbe5b8d0d05d44615a14339a6d41c", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_690e39f02fb881908b5a68acc28a4150", "custom_id": "request-13", "response": {"status_code": 400, "request_id": "be7c555968b3209549b89a7f5ff6c6c7", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_690e39f02c8081909e400a6b0e0412ce", "custom_id": "request-14", "response": {"status_code": 400, "request_id": "884fe961f441dd259331324e5b99777f", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_690e39f0393c81909a9e6dcfddb8caab", "custom_id": "request-15", "response": {"status_code": 400, "request_id": "afd29beb6ea22e12778a105c772e52ad", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_690e39f0330481908ac21e4102355cd7", "custom_id": "request-16", "response": {"status_code": 400, "request_id": "51045551e2ef618281cf7b8372b1d9e5", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_690e39f03af48190a62f7ad58e00c60a", "custom_id": "request-17", "response": {"status_code": 400, "request_id": "a2da7f5021d35a5c33c9849d6046bf85", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_690e39f043ac8190ada5f0ec019150c5", "custom_id": "request-18", "response": {"status_code": 400, "request_id": "56ac7aea08152ca55ee2723f8624f1b7", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_690e39f12ba08190b0b27b3c218c588c", "custom_id": "request-19", "response": {"status_code": 400, "request_id": "22195bdfe613ea379328c211707fae79", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_690e39f1a294819095ac2c055021bd1c", "custom_id": "request-20", "response": {"status_code": 400, "request_id": "6bb5cd12dfdd000d2b99a26582b88af2", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_690e39f1a7fc81909b9bee8427b91bb5", "custom_id": "request-21", "response": {"status_code": 400, "request_id": "ecea7be5b295457e852b7b49296923d2", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_690e39f154dc819082415adddf1c0223", "custom_id": "request-22", "response": {"status_code": 400, "request_id": "5b65ff490f057a797ef22f9368e0a512", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_690e39f1dcdc8190babb364ba36d093e", "custom_id": "request-23", "response": {"status_code": 400, "request_id": "b1a6f72caa78311c75818673251cf114", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_690e39f1418c81909b359096c8c9045d", "custom_id": "request-24", "response": {"status_code": 400, "request_id": "a148db3eff77107b0b25c488d8cbb33f", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_690e39f131308190a5a5d2f1d8b1a175", "custom_id": "request-25", "response": {"status_code": 400, "request_id": "f63e2ea485d23dbeaa5135e2e61768db", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_690e39f13f648190b34fe0b8544ede26", "custom_id": "request-26", "response": {"status_code": 400, "request_id": "57c3fbad95b5b8a0d6aaa360687199c4", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_690e39f139208190b8994f9b1d15ff6e", "custom_id": "request-27", "response": {"status_code": 400, "request_id": "0eff827d3bcecc4f1d50e22e421b9539", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_690e39f172b88190b7fbb922e9ad6e65", "custom_id": "request-28", "response": {"status_code": 400, "request_id": "e527bf8bdabf6abda760c9919b73e793", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_690e39f21f748190a003a077f391cde5", "custom_id": "request-29", "response": {"status_code": 400, "request_id": "69efbc65daf2ff03e48b3dd8da4a9668", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_690e39f21e888190bec6f800bbdd7434", "custom_id": "request-30", "response": {"status_code": 400, "request_id": "2c8d1f16148f6d9793e1c66423397564", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_690e39f2272c8190bcbeb85b5c249497", "custom_id": "request-31", "response": {"status_code": 400, "request_id": "4ae02bc3b34db7443307b5227f1e443e", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_690e39f23cdc8190ae72a73ae34c21cc", "custom_id": "request-32", "response": {"status_code": 400, "request_id": "df6d0d455499b0701defd3a009971042", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_690e39f235508190a73300d31794ecda", "custom_id": "request-33", "response": {"status_code": 400, "request_id": "0bf697cb1e9bcc02668614baf6ec9f3f", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_690e39f242c88190a922a11cbdb0c17a", "custom_id": "request-34", "response": {"status_code": 400, "request_id": "f8beb0f41d2930ec8bd58d4e6e1743db", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_690e39f28bf481909746c8e7d7a94b0f", "custom_id": "request-35", "response": {"status_code": 400, "request_id": "cebf0fcc2efe9d9e1334271bafed761d", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_690e39f2a5d88190b59d22b1c3b299f3", "custom_id": "request-36", "response": {"status_code": 400, "request_id": "6eab69690efa2c7be52f14ebb160dcb7", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_690e39f2aed48190945b3a6f79e22a1b", "custom_id": "request-37", "response": {"status_code": 400, "request_id": "7d764d155c49a7a1a3f4f0cf34119fc5", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_690e39f2e0f48190a4de1aaefb3597fd", "custom_id": "request-38", "response": {"status_code": 400, "request_id": "35042d17d38a19aaa5b53f3125b34225", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_690e39f31f648190b9bf8a16a652522e", "custom_id": "request-39", "response": {"status_code": 400, "request_id": "f11d52913de760c2eb51847d97a87a67", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_690e39f4397c8190bdf3bf9a47f7b219", "custom_id": "request-40", "response": {"status_code": 400, "request_id": "4288861bd28c628d1c56f147c3a53b6c", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_690e39f31cb48190bee6b03e81a1a48d", "custom_id": "request-41", "response": {"status_code": 400, "request_id": "df8be3a8af79a44c8f735aee5f6ad56d", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_690e39f3248c81909c402d0ca24c244e", "custom_id": "request-42", "response": {"status_code": 400, "request_id": "903676a58b3e65208eb3d25c71b6c77d", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_690e39f32b5081909d4fd00ecd0bc323", "custom_id": "request-43", "response": {"status_code": 400, "request_id": "138332e810b3b1750ad193e6e6cf57b8", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_690e39f346208190994424d1dd21f05c", "custom_id": "request-44", "response": {"status_code": 400, "request_id": "61d3c22976588b173a738cdeaebb7703", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_690e39f3833c8190a3adfe1a1919f211", "custom_id": "request-45", "response": {"status_code": 400, "request_id": "43f4db5353667e7c34efa95acaade31e", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_690e39f397788190b257109da521bccd", "custom_id": "request-46", "response": {"status_code": 400, "request_id": "8e5d64fcbb680aa94ea09a6d7c2c25e1", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_690e39f3a18481909301d86f8e08d2d9", "custom_id": "request-47", "response": {"status_code": 400, "request_id": "097967d14bb065dfa4c98fd1e83c5a03", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_690e39f3e5748190abcaa54020c5ebe1", "custom_id": "request-48", "response": {"status_code": 400, "request_id": "86681683bf2741fedd5f3fd9deef8afd", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_690e39f441e08190ab511c337cb26186", "custom_id": "request-49", "response": {"status_code": 400, "request_id": "4149e1fefb5533f9b99891991a91af59", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_690e39f572848190bf8dca2a9527819a", "custom_id": "request-50", "response": {"status_code": 400, "request_id": "48b99da1ec4aa1b08330c611781c21f4", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_690e39f4156c8190b2d51ae253a202bc", "custom_id": "request-51", "response": {"status_code": 400, "request_id": "3e8513777c22db94d6392cf4d943db65", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_690e39f4227881908bbae595efc2c7a6", "custom_id": "request-52", "response": {"status_code": 400, "request_id": "132bfabe9c4742fd72e8a688c0aee010", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_690e39f438348190b7b428b72cf9d678", "custom_id": "request-53", "response": {"status_code": 400, "request_id": "21c28f188368859587607756477e4cb5", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_690e39f472bc81909cbf1d7166e0c264", "custom_id": "request-54", "response": {"status_code": 400, "request_id": "90a0b899e9b47733cb9bb08f26fa4bfa", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_690e39f48b5c81908dfad353dfe3f851", "custom_id": "request-55", "response": {"status_code": 400, "request_id": "f11abdfb01840ea801058f52ad87f127", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_690e39f49b588190b057df3d32df723f", "custom_id": "request-56", "response": {"status_code": 400, "request_id": "14edec980d36929584f99fd6d550831f", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_690e39f4e4b481908d59fd4a573816c9", "custom_id": "request-57", "response": {"status_code": 400, "request_id": "2cf56ff7ecacdb9265c578f270d7dadb", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_690e39f51d108190ba064c6d65397be6", "custom_id": "request-58", "response": {"status_code": 400, "request_id": "a4c4080947874d2d97ff4eb42cb9b607", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_690e39f516d08190a01919baba2756f9", "custom_id": "request-59", "response": {"status_code": 400, "request_id": "9c6f3f5635ed4ff805ec092d09e7b54b", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_690e39f5363c8190a126aa45c199f921", "custom_id": "request-60", "response": {"status_code": 400, "request_id": "40b5ed81d9f7cd9f60aaf6707c67b984", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_690e39f529a48190807aa8d3df827bf3", "custom_id": "request-61", "response": {"status_code": 400, "request_id": "ecb916621c96e5e76f4a070b8d7b5d03", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_690e39f53a94819080be3619a366dca1", "custom_id": "request-62", "response": {"status_code": 400, "request_id": "cfe28f7b56ad4c72436a6232d9e635e9", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_690e39f561f8819088de85e70d26c23a", "custom_id": "request-63", "response": {"status_code": 400, "request_id": "f6310ab55102303faab256e590932c2a", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_690e39f579908190b0f11809877d8b08", "custom_id": "request-64", "response": {"status_code": 400, "request_id": "ec8f954adc3cf2ce73c48af2331a8af6", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_690e39f590348190b2722572e34161fa", "custom_id": "request-65", "response": {"status_code": 400, "request_id": "2edf7449175866b9dd6bc2d10c2b1e68", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_690e39f5ddc081909eff04ad36a362c3", "custom_id": "request-66", "response": {"status_code": 400, "request_id": "f6eb3d762e2240e2ced11d6b45045e8e", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_690e39f60f188190b1176eb00acff087", "custom_id": "request-67", "response": {"status_code": 400, "request_id": "de8b000566b0c0e5659995b56b24beab", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_690e39f61120819096239f0455e04e96", "custom_id": "request-68", "response": {"status_code": 400, "request_id": "97f42b5366d33ac53d9f7fced415ea6a", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_690e39f61cf88190a7bdaf4549a72953", "custom_id": "request-69", "response": {"status_code": 400, "request_id": "3d55a23b40bd3ec08055a32b7a836e9a", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_690e39f65284819085590b77a255a996", "custom_id": "request-70", "response": {"status_code": 400, "request_id": "4eb028044b90725d67e6207e7ef5abd8", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_690e39f627cc81908a278bf2858d7200", "custom_id": "request-71", "response": {"status_code": 400, "request_id": "8dd8a5e70c19b42123233e26fc12cf64", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_690e39f651f081909fa5235e505c7b39", "custom_id": "request-72", "response": {"status_code": 400, "request_id": "8f6fc1dd3a3c45d3dbca1091cf877a63", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_690e39f665bc819083f5e91b95b4f4bb", "custom_id": "request-73", "response": {"status_code": 400, "request_id": "7398d3ad72e53ab733d5b69482ef8812", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_690e39f66874819097c2cefea652d61b", "custom_id": "request-74", "response": {"status_code": 400, "request_id": "db107d03675f554905d57b10a8659c38", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_690e39f685b88190b63ab35706ec3666", "custom_id": "request-75", "response": {"status_code": 400, "request_id": "702a5cabf6eec72d5e870bd85030f9e9", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_690e39f6db0881908df0595ef973d6d2", "custom_id": "request-76", "response": {"status_code": 400, "request_id": "46ce10b026b7e601ab40deeb92d0d32b", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_690e39f703e48190a8d642f1ec56a597", "custom_id": "request-77", "response": {"status_code": 400, "request_id": "5bc1d4ccfd92f4c60404beeb4b3f1842", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_690e39f703d48190b11f9a376aa1586a", "custom_id": "request-78", "response": {"status_code": 400, "request_id": "e98b7409db1c8df1f15bcc9842c15814", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_690e39f70d8c81908e9702db9d79b888", "custom_id": "request-79", "response": {"status_code": 400, "request_id": "6fdde71d957e61bb37a0f38c2fce8a96", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_690e39f721f881908e699d0f0b145ae2", "custom_id": "request-80", "response": {"status_code": 400, "request_id": "30d03f719c9c8b3ebe23e349124c0f56", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_690e39f74b308190b14f7194bf45a624", "custom_id": "request-81", "response": {"status_code": 400, "request_id": "b0a93f3c73544c3836dcb2826fe8ae2c", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_690e39f7794c819099859077a9a48728", "custom_id": "request-82", "response": {"status_code": 400, "request_id": "fb103649911eac11b2c623f3d240c6f2", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_690e39f7550881908d17e9c5ca256d44", "custom_id": "request-83", "response": {"status_code": 400, "request_id": "4e1de0fd3eaa72accef1711a26d23d22", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_690e39f7585c819085eda96813e4cc26", "custom_id": "request-84", "response": {"status_code": 400, "request_id": "c215c68451963dda64c2d4027ffd731f", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_690e39f772a08190bb07554365daacae", "custom_id": "request-85", "response": {"status_code": 400, "request_id": "7a8106842c6f2400e81a71737e237def", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_690e39f7cd78819094a02050238d9ff1", "custom_id": "request-86", "response": {"status_code": 400, "request_id": "a2ffb98c786ad5bde06b70492d6b3e1e", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_690e39f803a48190b3ed5277cad2c191", "custom_id": "request-87", "response": {"status_code": 400, "request_id": "28bc855ed5d2b32fb93eb6e0b788538b", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_690e39f7f5f08190b4f64ff1d049da57", "custom_id": "request-88", "response": {"status_code": 400, "request_id": "f05deaca73dfaaa4dd23bbf24d6f2357", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_690e39f80b8c819091c51805ee225e74", "custom_id": "request-89", "response": {"status_code": 400, "request_id": "14846016337ee0edd2ea1bac53972a33", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_690e39f812ac81908669f696e5c97bef", "custom_id": "request-90", "response": {"status_code": 400, "request_id": "6d0c0bca59ec9be5a68f1def4bf240a8", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_690e39f8473c81909096690c2cce1bdf", "custom_id": "request-91", "response": {"status_code": 400, "request_id": "61c47590be036e925958b9d39f636aae", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_690e39f854c88190a457f9ac7b081a19", "custom_id": "request-92", "response": {"status_code": 400, "request_id": "7bee44f77349a4c6bbdf49a3a796b567", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_690e39f85b108190a4ba711a60d800b4", "custom_id": "request-93", "response": {"status_code": 400, "request_id": "01f14f89b9bfc6e7e71575cd89219454", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_690e39f874208190a3684c4d2f18d32e", "custom_id": "request-94", "response": {"status_code": 400, "request_id": "e51ba7c42123f47321632076217c3fbf", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_690e39f8692481909e4855d4c410aa19", "custom_id": "request-95", "response": {"status_code": 400, "request_id": "de3f7ed7159e61e1c19ed3722353cece", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_690e39f8c4088190916b04195cafe169", "custom_id": "request-96", "response": {"status_code": 400, "request_id": "5bd275c793ca297ed66065a0a93a78e4", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_690e39f8ec508190bf865387a83ff5c7", "custom_id": "request-97", "response": {"status_code": 400, "request_id": "72715d501f9263170928f286dd57bbb7", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_690e39f8f538819082b3f34e0bba222b", "custom_id": "request-98", "response": {"status_code": 400, "request_id": "4b1ff222625c64a64de56b05f1a2cbb7", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_690e39f90f048190b180b0519be20d7c", "custom_id": "request-99", "response": {"status_code": 400, "request_id": "2b35685c1f29808b38f38f5e57542066", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
